{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5714ca4-dfff-4d45-b19d-46eaaa2ebf9c",
      "metadata": {
        "id": "f5714ca4-dfff-4d45-b19d-46eaaa2ebf9c",
        "outputId": "fa250bec-2a1f-4440-bfca-f908d632bcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mask: tensor([[[False,  True],\n",
            "         [False, False]]])\n",
            "tensor([[[ 0.0391,  0.0267, -0.0697],\n",
            "         [-0.0258, -0.0258,  0.0583]]], grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the input tensor\n",
        "x = torch.tensor([[[-0.1, 0.1,  0.3],\n",
        "                   [ 0.4, -1.1, -0.3]]])\n",
        "\n",
        "# Create the multi-head attention layer\n",
        "layer = nn.MultiheadAttention(embed_dim=3, num_heads=1, bias=False, batch_first=True)\n",
        "\n",
        "custom_weights = torch.tensor( [[-0.3561,  0.3674, -0.5108],\n",
        "                                [ 0.5146, -0.4764, -0.1490],\n",
        "                                [ 0.5072, -0.2932, -0.5633],\n",
        "                                [-0.4932, -0.4468,  0.0736],\n",
        "                                [-0.6879, -0.4689, -0.1026],\n",
        "                                [ 0.1847,  0.1858,  0.4469],\n",
        "                                [-0.4110, -0.4083, -0.5549],\n",
        "                                [ 0.3921, -0.0746, -0.1336],\n",
        "                                [-0.6555, -0.3418, -0.2980]]).float()\n",
        "layer.in_proj_weight = nn.Parameter(custom_weights)\n",
        "\n",
        "custom_out_proj = torch.tensor([[-0.3601,  0.2771, -0.0573],\n",
        "                                [-0.0896,  0.0567, -0.2882],\n",
        "                                [ 0.3200,  0.1517,  0.0580]]).float()\n",
        "layer.out_proj.weight = nn.Parameter(custom_out_proj)\n",
        "\n",
        "# Create an upper triangular mask for causal attention\n",
        "# Adjust the size as per your sequence length\n",
        "mask = torch.triu(torch.ones(1, 2, 2), diagonal=1).bool()\n",
        "print(f'mask: {mask}')\n",
        "\n",
        "# Perform the forward pass\n",
        "# You can use x for both queries, keys, and values in this example\n",
        "output_tensor, attn_output_weights = layer(x, x, x, attn_mask=mask)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb68d0a-00d5-4c66-b04a-207eab1514bd",
      "metadata": {
        "id": "8bb68d0a-00d5-4c66-b04a-207eab1514bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75dc9c0b-fc88-4ea1-883e-743b9681bdf0",
      "metadata": {
        "id": "75dc9c0b-fc88-4ea1-883e-743b9681bdf0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "adbbcc92-1f17-4dd2-b0d8-74d22a0bd4ba",
      "metadata": {
        "id": "adbbcc92-1f17-4dd2-b0d8-74d22a0bd4ba"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032939ff",
      "metadata": {
        "id": "032939ff",
        "outputId": "09a540ed-dce6-43e8-a6f5-dacf06c62cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attention_weights: tensor([[[[1.0000, 0.0000],\n",
            "          [0.5225, 0.4775]]]], grad_fn=<SoftmaxBackward0>)\n",
            "context: tensor([[[[-0.1662, -0.0868, -0.0580],\n",
            "          [ 0.1286,  0.0879,  0.0667]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "tensor([[[ 0.0391,  0.0267, -0.0697],\n",
            "         [-0.0258, -0.0258,  0.0583]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the input tensor\n",
        "x = torch.tensor([[[-0.1, 0.1,  0.3],\n",
        "                   [ 0.4, -1.1, -0.3]]])\n",
        "\n",
        "q = torch.tensor(  [[-0.3561,  0.3674, -0.5108],\n",
        "                    [ 0.5146, -0.4764, -0.1490],\n",
        "                    [ 0.5072, -0.2932, -0.5633]]).float()\n",
        "k = torch.tensor(  [[-0.4932, -0.4468,  0.0736],\n",
        "                    [-0.6879, -0.4689, -0.1026],\n",
        "                    [ 0.1847,  0.1858,  0.4469]]).float()\n",
        "v = torch.tensor(  [[-0.4110, -0.4083, -0.5549],\n",
        "                    [ 0.3921, -0.0746, -0.1336],\n",
        "                    [-0.6555, -0.3418, -0.2980]]).float()\n",
        "o = torch.tensor([[-0.3601,  0.2771, -0.0573],\n",
        "                  [-0.0896,  0.0567, -0.2882],\n",
        "                  [ 0.3200,  0.1517,  0.0580]]).float()\n",
        "\n",
        "# Define the model parameters\n",
        "embed_dim = 3\n",
        "num_heads = 1\n",
        "head_dim = embed_dim // num_heads\n",
        "\n",
        "# Step 1: Linear projections for queries, keys, and values\n",
        "query_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "key_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "value_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "\n",
        "# Custom weights for linear projections\n",
        "query_proj.weight = nn.Parameter(q)\n",
        "key_proj.weight = nn.Parameter(k)\n",
        "value_proj.weight = nn.Parameter(v)\n",
        "\n",
        "# Step 2: Split the input into multiple heads\n",
        "query = query_proj(x)\n",
        "key = key_proj(x)\n",
        "value = value_proj(x)\n",
        "\n",
        "# Reshape query, key, and value to have shape (batch_size, num_heads, seq_len, head_dim)\n",
        "query = query.view(1, num_heads, -1, head_dim)\n",
        "key = key.view(1, num_heads, -1, head_dim)\n",
        "value = value.view(1, num_heads, -1, head_dim)\n",
        "\n",
        "# Step 3: Compute scaled dot-product attention with masking\n",
        "attention_scores = torch.matmul(query, key.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "\n",
        "# Create a mask to enforce causal attention\n",
        "seq_len = attention_scores.size(-1)\n",
        "mask = torch.triu(torch.ones(1, 1, seq_len, seq_len), diagonal=1).bool()\n",
        "\n",
        "# Apply the mask by setting masked positions to a large negative value\n",
        "attention_scores = attention_scores.masked_fill(mask, float(\"-inf\"))\n",
        "\n",
        "attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "context = torch.matmul(attention_weights, value)\n",
        "\n",
        "print('attention_weights:', attention_weights)\n",
        "print('context:', context)\n",
        "\n",
        "# Step 4: Concatenate and project back\n",
        "context = context.view(1, -1, embed_dim)\n",
        "\n",
        "out_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "out_proj.weight = nn.Parameter(o)\n",
        "output = out_proj(context)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151b398d",
      "metadata": {
        "id": "151b398d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba1ed2f1",
      "metadata": {
        "id": "ba1ed2f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd24cd33",
      "metadata": {
        "id": "fd24cd33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa802bc6",
      "metadata": {
        "id": "fa802bc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a08508c6",
      "metadata": {
        "id": "a08508c6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71576a7d",
      "metadata": {
        "id": "71576a7d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60c04f27",
      "metadata": {
        "id": "60c04f27"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8c7f60",
      "metadata": {
        "id": "bf8c7f60"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}