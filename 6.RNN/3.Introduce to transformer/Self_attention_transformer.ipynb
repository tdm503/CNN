{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9AJSBM1ORspW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[[-0.1, 0.1,  0.3]]])\n",
        "layer = nn.MultiheadAttention(embed_dim=3, num_heads=1, bias=False, batch_first=True)\n",
        "\n",
        "layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN2p67ewR19J",
        "outputId": "273539ae-a9c2-402e-8e06-e360614fb8c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_tensor, attn_output_weights = layer(x, x, x)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G9niPq-VNd6",
        "outputId": "09b66514-6bf4-4839-a5b2-d65cdf108823"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0255, -0.0356,  0.0286]]], grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "x = torch.tensor([[[-0.1, 0.1, 0.3]]])\n",
        "\n",
        "q = torch.tensor(  [[-0.3561,  0.3674, -0.5108],\n",
        "                    [ 0.5146, -0.4764, -0.1490],\n",
        "                    [ 0.5072, -0.2932, -0.5633]]).float()\n",
        "k = torch.tensor(  [[-0.4932, -0.4468,  0.0736],\n",
        "                    [-0.6879, -0.4689, -0.1026],\n",
        "                    [ 0.1847,  0.1858,  0.4469]]).float()\n",
        "v = torch.tensor(  [[-0.4110, -0.4083, -0.5549],\n",
        "                    [ 0.3921, -0.0746, -0.1336],\n",
        "                    [-0.6555, -0.3418, -0.2980]]).float()\n",
        "o = torch.tensor([[-0.3601,  0.2771, -0.0573],\n",
        "                  [-0.0896,  0.0567, -0.2882],\n",
        "                  [ 0.3200,  0.1517,  0.0580]]).float()\n",
        "query = x@q.T\n",
        "key = x@k.T\n",
        "value = x@v.T\n",
        "\n",
        "# Define the model parameters\n",
        "embed_dim = 3\n",
        "num_heads = 1\n",
        "head_dim = embed_dim // num_heads\n",
        "\n",
        "# Reshape query, key, and value to have shape (batch_size, num_heads, seq_len, head_dim)\n",
        "query = query.view(num_heads, -1, head_dim)\n",
        "key = key.view(num_heads, -1, head_dim)\n",
        "value = value.view(num_heads, -1, head_dim)\n",
        "\n",
        "query\n",
        "\n",
        "# Step 3: Compute scaled dot-product attention\n",
        "attention_scores = torch.matmul(query, key.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "context = torch.matmul(attention_weights, value)\n",
        "\n",
        "\n",
        "print('attention_scores', attention_scores)\n",
        "print('attention_weights', attention_weights)\n",
        "print('context', context)\n",
        "\n",
        "\n",
        "# Step 4: Concatenate and project back\n",
        "context = context.view(-1, embed_dim)\n",
        "output = context@o.T\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPOS-J7AVPts",
        "outputId": "ced52154-82e3-46f3-9352-a5a2bf99d177"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_scores tensor([[[-0.0198]]])\n",
            "attention_weights tensor([[[1.]]])\n",
            "context tensor([[[-0.1662, -0.0868, -0.0580]]])\n",
            "tensor([[ 0.0391,  0.0267, -0.0697]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CByC4qMbbhIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}