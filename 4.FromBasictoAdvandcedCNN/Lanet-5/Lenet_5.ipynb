{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KL7SoF_1AQto"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85-FQY8KCbuj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLenet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(myLenet,self).__init__()\n",
        "    self.layer1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,stride=1)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    self.tan1 = nn.ReLU(inplace=True)\n",
        "    self.layer2 = nn.Conv2d(6,16,5)\n",
        "    self.pool2 = nn.MaxPool2d(2,2)\n",
        "    self.tan2 = nn.ReLU(inplace=True)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.FC1 = nn.Linear(16*5*5,84)\n",
        "    self.tan3 = nn.ReLU(inplace=True)\n",
        "    self.FC2 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.tan1(self.pool1(self.layer1(x)))\n",
        "    x = self.tan2(self.pool2(self.layer2(x)))\n",
        "    x = self.flatten(x)\n",
        "    x = self.tan3(self.FC1(x))\n",
        "    x = self.FC2(x)\n",
        "\n",
        "    return x\n",
        ""
      ],
      "metadata": {
        "id": "c93-jTAxAVsB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "0OCO7bymCsVJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D97lx5JwC90d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lenet for CIFAR10"
      ],
      "metadata": {
        "id": "6Vwu9yL5MdOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "A1cehWD-MfIK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "CqDvdFksMgyu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNtmzb4ZNVls",
        "outputId": "c0b0b06e-b29f-4b6f-92c1-f191119fda11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 81903104.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL"
      ],
      "metadata": {
        "id": "v9OaGruWNmxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class lenetCNN(nn.Module):\n",
        "  def __init__(self, imdim=3, num_classes=10):\n",
        "    super(lenetCNN,self).__init__()\n",
        "    self.layer1 = nn.Conv2d(imdim,64,5)\n",
        "    self.mp1 = nn.MaxPool2d(2)\n",
        "    self.ac1 = nn.ReLU(inplace=True)\n",
        "    self.layer2 = nn.Conv2d(64,128,5)\n",
        "    self.mp2 = nn.MaxPool2d(2)\n",
        "    self.ac2 = nn.ReLU(inplace=True)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.FC1 = nn.Linear(128*5*5,1024)\n",
        "    self.ac3 = nn.ReLU()\n",
        "    self.FC2 = nn.Linear(1024,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.ac1(self.mp1(self.layer1(x)))\n",
        "    x = self.ac2(self.mp2(self.layer2(x)))\n",
        "    x = self.flatten(x)\n",
        "    x = self.ac3(self.FC1(x))\n",
        "    x = self.FC2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "ZsJpBgS0NnqW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lenetCNN()"
      ],
      "metadata": {
        "id": "o4grjfDniQuw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "zlO7xOlheVkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "Lt89U_F9d-td"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_total = []\n",
        "accuracy = []\n",
        "max_epoch = 10"
      ],
      "metadata": {
        "id": "Rrmsg1iKef35"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "kJUvwQhXinZd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(max_epoch):\n",
        "  model.train()\n",
        "  cnt_acc,cnt_total = 0,0\n",
        "  losses = []\n",
        "  for idx,(inputs,outputs) in enumerate(trainloader):\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = outputs.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    pred = model(inputs)\n",
        "    loss = criterion(pred,outputs)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #cal accuracy\n",
        "    _, predicted = torch.max(pred.data, 1)\n",
        "    cnt_acc += (predicted == outputs).sum().item()\n",
        "    cnt_total += outputs.size(0)\n",
        "  accuracy = 100 * cnt_acc / cnt_total\n",
        "  test_loss = sum(losses) / len(losses)\n",
        "  print(f\"epoch : {i} | acc : {accuracy} | loss : {test_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvukSNxZerwl",
        "outputId": "b29bf066-1269-454e-e116-ddfe67f031cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0 | acc : 45.07 | loss : 1.5018063187599182\n",
            "epoch : 1 | acc : 60.342 | loss : 1.1077983324625054\n",
            "epoch : 2 | acc : 67.896 | loss : 0.9082521008593696\n",
            "epoch : 3 | acc : 72.72 | loss : 0.781157235405883\n",
            "epoch : 4 | acc : 76.012 | loss : 0.6803731620311737\n",
            "epoch : 5 | acc : 79.37 | loss : 0.585021584313743\n",
            "epoch : 6 | acc : 83.14 | loss : 0.48300820953991946\n",
            "epoch : 7 | acc : 86.26 | loss : 0.39195807567056345\n",
            "epoch : 8 | acc : 89.694 | loss : 0.3026476597451434\n",
            "epoch : 9 | acc : 91.994 | loss : 0.23697072001440184\n"
          ]
        }
      ]
    }
  ]
}